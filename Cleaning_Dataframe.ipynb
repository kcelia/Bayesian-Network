{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import types\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from functools import partial\n",
    "from typing import List, Callable\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import networkx \n",
    "\n",
    "from pyvis.network import Network\n",
    "from pomegranate import BayesianNetwork\n",
    "\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename: str=\"data/corona.csv\") -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a file \n",
    "    \n",
    "    :param filename: File's name\n",
    "    \n",
    "    :return: The dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filename).dropna(how=\"all\").drop_duplicates()\n",
    "    except:\n",
    "        print(f\"Error occurred while reading the file {filename}\")\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingOrder:\n",
    "    \"\"\"\n",
    "    This function imposes an ORDER of execution (some operations must be executed before others).\n",
    "    It allows the execution of several processing's method entered bu a user in the form of list, \n",
    "    The input list might be in the wrong order, this function will manage the order for us \n",
    "    Order of priority : DESCENDING (order(1) must be exceuted before order(2)) \n",
    "    \"\"\"\n",
    "    # variable static\n",
    "    execution_plan = {}\n",
    "    private_methods = []\n",
    "    \n",
    "    def __init__(self, o):\n",
    "        self.o = o\n",
    "    \n",
    "    def __call__(self, f):\n",
    "        ProcessingOrder.execution_plan[self.o] = f\n",
    "        assert f.__name__.startswith('__')\n",
    "        ProcessingOrder.private_methods.append(f.__name__[2:])\n",
    "        return f\n",
    "\n",
    "order = ProcessingOrder\n",
    "\n",
    "class ProcessingC:\n",
    "    \n",
    "    def __private_wrapper(self, fname, **kwargs):\n",
    "        self.__m[fname] = kwargs\n",
    "        return self\n",
    "\n",
    "\n",
    "    def __init__(self, steps={}):\n",
    "        self.__m = {} #__methods_arguments\n",
    "        \n",
    "        # Create public interfaces of the private methods\n",
    "        for m in ProcessingOrder.private_methods:\n",
    "            self.__dict__[m] = types.MethodType(partial(ProcessingC.__private_wrapper, fname=m), self)\n",
    "       \n",
    "        # Add arguments of stemps to the methods arguments memory (or update if already exists)\n",
    "        for method, kwargs in steps.items():\n",
    "            self.__getattribute__(method)(**kwargs)\n",
    "            print(method.upper(), \"append\", kwargs)\n",
    "        \n",
    "\n",
    "    @order(1)\n",
    "    def __read_csv(self, df) -> None:\n",
    "        \"\"\"\n",
    "        We can provide directly a Dataframe, or the path of file \n",
    "        \"\"\"\n",
    "        self.data = read_file(filename=df) if type(df) == str else df\n",
    "    \n",
    "    @order(2)\n",
    "    def __rename_columns(self, columns: dict = {}, uppercase: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Column renaming\n",
    "        :param columns: Concerned column\n",
    "        :param uppercase: if \"True\" uppercase columns else put only the first letter in uppercase \n",
    "        \"\"\"\n",
    "        self.data.rename(columns=columns, inplace=True)\n",
    "        self.data.columns = self.data.columns.str.strip().str.upper() if uppercase \\\n",
    "                            else self.data.columns.str.strip().str.title()\n",
    "            \n",
    "    @order(3)\n",
    "    def __drop_useless_feature(self, columns: List[str] = [], frac_col: float = .7, frac_row: float = .45) -> None:\n",
    "        \"\"\"\n",
    "        This function removes a list of input columns and the columns/rows, \n",
    "        that contain many missing values from the dataframe\n",
    "        :param columns: List of columns to be removed\n",
    "        :param frac_col: Delete columns that have a factor of frac_col * len(df) of missing values\n",
    "        :param frac_row: Delete rows that have a factor of frac_row * len(df) of missing values\n",
    "        \n",
    "        \"\"\"\n",
    "        # Find the columns that contain more than frac_col * len(df)\n",
    "        drop_columns = [column for column, value in self.data.isnull().sum(0).to_dict().items() \n",
    "                            if value >= frac_col * self.data.shape[0]]\n",
    "        # Delete both the list of the input columns and the computed column above\n",
    "        self.data.drop(columns=columns + drop_columns, inplace=True)\n",
    "        # Find the rows that contain more than frac_row * len(df)\n",
    "        self.data.drop(self.data[self.data.isnull().sum(1) >= frac_row * self.data.shape[1]].index, inplace=True)\n",
    "        \n",
    "    @order(4)\n",
    "    def __to_date(self, pattern: str = r'\\d{2,3}\\W{1}\\d{2}\\W{1}\\d{2,3}\\s*(\\d{2}:\\d{2}:\\d{2})?', n: int = 3) -> None:\n",
    "        \"\"\"\n",
    "        Often the dates in a dataframe are in string format when they should be in datatime format \n",
    "        This function finds the columns that contain dates according to a pattern.\n",
    "        \n",
    "        :param pattern: How a date format can be found in a df\n",
    "        :param n: When you find columns that contain potential dates (here, date_col), we apply a health check \n",
    "        to a random set of values to ensure that the contains looks like a date format\n",
    "        \n",
    "        After retrieving the relevant columns, we convert them into a cyclic feature to allow the Machine Learning \n",
    "        algorithm to better understand this feature (it occurs in cycles rather than ascenfing values)\n",
    "        \n",
    "        A common method for encoding cyclical data is to transform the data into \n",
    "        two dimensions using a sine and consine transformation over years, months, days, hours ...\n",
    "        Here I choose to deal with months and days \n",
    "        \n",
    "        For more details, see: https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning\n",
    "        \"\"\"              \n",
    "        \n",
    "        health_check = lambda column: (sum([bool(re.search(pattern, value)) for value in self.data[column].sample(n)])) == n     \n",
    "        date_columns = [column for column in self.data.columns \n",
    "                        if re.search(\"date\", column.lower()) and health_check(column)]\n",
    "        \n",
    "        for col in date_columns:            \n",
    "            # Convert to datetime format\n",
    "            self.data[col] = pd.to_datetime(self.data[col]) #, errors=\"NoteDate\")  \n",
    "            # The date is a cycling feature\n",
    "            self.data[f\"{col}_month_sin\"] = np.sin(2 * np.pi * self.data[col].dt.month / 12)\n",
    "            self.data[f\"{col}_month_con\"] = np.cos(2 * np.pi * self.data[col].dt.month / 12)\n",
    "            self.data[f\"{col}_day_sin\"]   = np.sin(2 * np.pi * self.data[col].dt.day / 31)\n",
    "            self.data[f\"{col}_day_con\"]   = np.cos(2 * np.pi * self.data[col].dt.day / 31)\n",
    "            \n",
    "        # Save the original data \n",
    "        self.date_columns_copy = self.data[date_columns].copy()\n",
    "        # Delete the column, because it's useless afterwards\n",
    "        self.data.drop(columns=date_columns, inplace=True)\n",
    "        \n",
    "    @order(5)\n",
    "    def __missing_values(self, method: str = \"median\", n_clusters: int = 4):\n",
    "        \"\"\"\"\n",
    "        Replace the missing values according to a input method\n",
    "        :param method: The strategy used to replace the missing values, it can be: median, mean or other \n",
    "        \"\"\"\n",
    "        # Save the id of nan index df[np.isnan(df['b'])] \n",
    "        self.mv = {col: self.data[np.isnan(self.data[col])].index.tolist() \n",
    "                   for col in self.data.columns[self.data.isna().any()].tolist()}\n",
    "        if method == \"mean\":\n",
    "            self.data.fillna(self.data.mean(), inplace=True)\n",
    "        elif method == \"median\":\n",
    "            self.data.fillna(self.data.median(), inplace=True)       \n",
    "        else:\n",
    "            try:\n",
    "                df[col].fillna(method=method, inplace=True)\n",
    "            except: print(f\"Error Fillna: method {method}, isn't implemented\")\n",
    "                \n",
    "        # We cannot apply median or mean on string columns\n",
    "        for col in self.data.select_dtypes(include=['object']).columns: # Find string type columns\n",
    "            self.data[col] = self.data[col].fillna(\"NaN\") # Replace with a string, the NaN type is not supported by the algorithms. \n",
    "        \n",
    "        # Go furtherto \n",
    "        # Kmeans ???? \n",
    "        # How should I do with sting type columns ? One Hot Encoding ??\n",
    "        # Pandas provides OHE with pd.get_dummies(df,prefix=[col]), but it will create a column for each values\n",
    "        # But, our models are sensitive to the number of variables        \n",
    "        \n",
    "    @order(6)\n",
    "    def __continuous_to_categorial(self, transform: dict = {}, threshold: int = 10, \n",
    "                                 interval: int = 5, nb_point: int = 4):\n",
    "        \"\"\"\n",
    "        Transform continuous variables to categorial variables \n",
    "        :param transform: A processing method is specified for each set of columns  \n",
    "        :param threshold: The minimum number of states, that a variable can has\n",
    "        :param interval : How much value are there in a bins\n",
    "        :param nb_points: Minimum number of points in a cluster\n",
    "        \"\"\"\n",
    "        # Find all continuous columns that should be converted, according to a givin threshold\n",
    "        all_cc = list(filter(lambda col: self.data[col].nunique() >= threshold, self.data.columns))\n",
    "        # Find string type columns \n",
    "        str_cc = list(self.data.select_dtypes(include=['object']).columns)\n",
    "        # Put in the right format the list of columns to convert \n",
    "        #print(\"columns\", self.data.columns)\n",
    "        print(\"tran\", transform)\n",
    "        input_c = np.array(list(itertools.chain.from_iterable(transform.values())))[:, 0].tolist() if len(transform) else []\n",
    "        print(\"str\", str_cc)\n",
    "        print(\"input\", input_c)\n",
    "        # Find the rest of the variables that have not been givin \n",
    "        to_discret = list(filter(lambda col: col not in input_c and col not in str_cc, all_cc))\n",
    "        print(\"rest\", to_discret)\n",
    "        \n",
    "        for method, columns in transform.items():\n",
    "            if method[0] == \"qcut\":\n",
    "                for col in columns:                    \n",
    "                    # Compte the appropriate number of bins for a given column\n",
    "                    bins = int(len(self.data[col]) / interval) if not method[1] else method[1]\n",
    "                    # If an Erro occurs here, check the bins and interval\n",
    "                    #print(f\"Col: {col}, Error bins = {bins}, distinct values {self.data[col].nunique()}, decrease the number of interval {interval}\")\n",
    "                    self.data[col] = pd.qcut(self.data[col].values, bins)                        \n",
    "            elif method[0] == \"kmeans\":\n",
    "                for col in columns:\n",
    "                    # Compte the appropriate number of cluster for a given column\n",
    "                    n_clusters = int(len(self.data[col]) / nb_points) if not method[1] else method[1]\n",
    "                    kmeans = KMeans(n_clusters=n_clusters).fit(self.data[col].values.reshape(-1, 1))\n",
    "                    self.data[col] = kmeans.predict(self.data[col].values.reshape(-1, 1)) \n",
    "            # else EM\n",
    "        # The remain column to be converted, the default method is qcut\n",
    "        for col in to_discret:\n",
    "            bins = int(len(self.data[col]) / interval)\n",
    "            # If an Erro occurs here, check the bins and interval\n",
    "            #print(f\"Col: {col}, Error bins = {bins}, distinct values {self.data[col].nunique()}, decrease the number of interval {interval}\")\n",
    "    \n",
    "            self.data[col] = pd.qcut(self.data[col].values, bins, duplicates=\"drop\")\n",
    "\n",
    "    def fit(self):\n",
    "        # Excetute the plan in the right order (only the function specified by the builder or the steps)\n",
    "        for o, f in sorted(ProcessingOrder.execution_plan.items()):\n",
    "            if f.__name__[2:] in self.__m:\n",
    "                self.__getattribute__(f\"_{self.__class__.__name__}{f.__name__}\")(**self.__m[f.__name__[2:]])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ_CSV append {'df': 'data/heart.csv'}\n",
      "RENAME_COLUMNS append {'columns': {'trestbps': 'TREST_BPS', 'restecg': 'REST_ECG', 'exang': 'ANG'}, 'uppercase': 'upper'}\n",
      "DROP_USELESS_FEATURE append {'columns': ['TREST_BPS', 'REST_ECG', 'SLOPE', 'THAL', 'CHOL', 'FBS']}\n",
      "TO_DATE append {'n': 3}\n",
      "MISSING_VALUES append {'method': 'median'}\n",
      "CONTINUOUS_TO_CATEGORIAL append {'transform': {'qcut': [('THALACH', 3)]}, 'interval': 30, 'threshold': 10}\n",
      "tran {'qcut': [('THALACH', 3)]}\n",
      "str []\n",
      "input ['THALACH']\n",
      "rest ['AGE', 'OLDPEAK']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CP</th>\n",
       "      <th>THALACH</th>\n",
       "      <th>ANG</th>\n",
       "      <th>OLDPEAK</th>\n",
       "      <th>CA</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(62.0, 66.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.9, 2.8]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(28.999, 42.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.8, 6.2]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(28.999, 42.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.16, 1.4]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(55.5, 58.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.4, 0.8]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(55.5, 58.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.4, 0.8]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>(55.5, 58.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.001, 0.4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>(42.0, 45.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.16, 1.4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>(66.0, 77.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.8, 6.2]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>(55.5, 58.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>(1.16, 1.4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>(55.5, 58.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.001, 0.4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGE  SEX  CP  THALACH  ANG        OLDPEAK  CA  TARGET\n",
       "0      (62.0, 66.0]    1   3      150    0     (1.9, 2.8]   0       1\n",
       "1    (28.999, 42.0]    1   2      187    0     (2.8, 6.2]   0       1\n",
       "2    (28.999, 42.0]    0   1      172    0    (1.16, 1.4]   0       1\n",
       "3      (55.5, 58.0]    1   1      178    0     (0.4, 0.8]   0       1\n",
       "4      (55.5, 58.0]    0   0      163    1     (0.4, 0.8]   0       1\n",
       "..              ...  ...  ..      ...  ...            ...  ..     ...\n",
       "298    (55.5, 58.0]    0   0      123    1  (-0.001, 0.4]   0       0\n",
       "299    (42.0, 45.0]    1   3      132    0    (1.16, 1.4]   0       0\n",
       "300    (66.0, 77.0]    1   0      141    0     (2.8, 6.2]   2       0\n",
       "301    (55.5, 58.0]    1   0      115    1    (1.16, 1.4]   1       0\n",
       "302    (55.5, 58.0]    0   1      174    0  (-0.001, 0.4]   1       0\n",
       "\n",
       "[302 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example execution\n",
    "p = ProcessingC(steps={\n",
    "    'read_csv': \n",
    "        {'df': \"data/heart.csv\"},\n",
    "    'rename_columns': \n",
    "        {'columns': {\"trestbps\": \"TREST_BPS\", \"restecg\":\"REST_ECG\", \"exang\":\"ANG\"}, 'uppercase': \"upper\"},\n",
    "    'drop_useless_feature': \n",
    "        {'columns': ['TREST_BPS', 'REST_ECG', 'SLOPE',  'THAL', 'CHOL', 'FBS']},\n",
    "    'to_date': {'n': 3},\n",
    "    'missing_values': {'method': \"median\"}, \n",
    "    'continuous_to_categorial': {'transform': {'qcut': [(\"THALACH\", 3)]}, 'interval': 30, 'threshold': 10}\n",
    "}).fit()\n",
    "p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ_CSV append {'df': 'data/corona.csv'}\n",
      "RENAME_COLUMNS append {'columns': {}, 'uppercase': 'upper'}\n",
      "DROP_USELESS_FEATURE append {'columns': ['STATE']}\n",
      "TO_DATE append {'n': 3}\n",
      "MISSING_VALUES append {'method': 'median'}\n",
      "CONTINUOUS_TO_CATEGORIAL append {'interval': 100, 'threshold': 10}\n",
      "tran {}\n",
      "str ['STATE ABBREVIATION']\n",
      "input []\n",
      "rest ['POPULATION', 'TOTAL GDP LAST Q (X 1 MIL.)', 'GDP/CAPITA', '# RESIDENTS/SQUARE MILE', '# OF CONFIRMED CASES', '# OF CONFIRMED CASES PER 100K', 'DAYS SINCE BAR/RESTAURANT LIMITS', 'DAYS SINCE COST-SHARING WAIVER (TREATMENT)', 'DAYS SINCE EARLY RX REFILL', 'DAYS SINCE EMERGENCY DECLARATION', 'DAYS SINCE EXECUTIVE ORDER MANDATING COMPLIANCE WITH STATE GUIDANCE', 'DAYS SINCE FREE VACCINE', 'DAYS SINCE LARGE GATHERINGS BAN', 'DAYS SINCE MANDATORY QUARANTINE', 'DAYS SINCE MARKETPLACE SEP', 'DAYS SINCE NON-ESSENTIAL BUSINESS CLOSURES', 'DAYS SINCE PAID SICK LEAVE', 'DAYS SINCE PEACETIME EMERGENCY', 'DAYS SINCE PRIMARY ELECTION POSTPONEMENT', 'DAYS SINCE PUBLIC HEALTH EMERGENCY', 'DAYS SINCE SCHOOL CLOSURES', 'DAYS SINCE SECTION 1135 WAIVER', 'DAYS SINCE WAIVE PRIOR AUTH', 'NEW CASES PER 100K 15 DAYS LATER', 'NUMBER OF ACTIVE NPIS', 'DATE_day_sin', 'DATE_day_con']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE ABBREVIATION</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>TOTAL GDP LAST Q (X 1 MIL.)</th>\n",
       "      <th>GDP/CAPITA</th>\n",
       "      <th>IS BORDER STATE</th>\n",
       "      <th># RESIDENTS/SQUARE MILE</th>\n",
       "      <th># OF CONFIRMED CASES</th>\n",
       "      <th># OF CONFIRMED CASES PER 100K</th>\n",
       "      <th>DAYS SINCE BAR/RESTAURANT LIMITS</th>\n",
       "      <th>DAYS SINCE CIVIL PREPAREDNESS EMERGENCY</th>\n",
       "      <th>...</th>\n",
       "      <th>PUBLIC HEALTH EMERGENCY</th>\n",
       "      <th>SCHOOL CLOSURES</th>\n",
       "      <th>SECTION 1135 WAIVER</th>\n",
       "      <th>WAIVE PRIOR AUTH</th>\n",
       "      <th>NEW CASES PER 100K 15 DAYS LATER</th>\n",
       "      <th>NUMBER OF ACTIVE NPIS</th>\n",
       "      <th>DATE_month_sin</th>\n",
       "      <th>DATE_month_con</th>\n",
       "      <th>DATE_day_sin</th>\n",
       "      <th>DATE_day_con</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>(4467673.0, 5639632.0]</td>\n",
       "      <td>(195858.0, 247711.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(74.6, 111.0]</td>\n",
       "      <td>(-1.001, 0.0]</td>\n",
       "      <td>(-0.0335, 0.0]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.0204, 0.133]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>(-0.651, -0.394]</td>\n",
       "      <td>(0.689, 0.919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>(4467673.0, 5639632.0]</td>\n",
       "      <td>(195858.0, 247711.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(74.6, 111.0]</td>\n",
       "      <td>(-1.001, 0.0]</td>\n",
       "      <td>(-0.0335, 0.0]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.133, 0.354]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(-0.101, 0.25]</td>\n",
       "      <td>(0.919, 0.98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AL</td>\n",
       "      <td>(4467673.0, 5639632.0]</td>\n",
       "      <td>(195858.0, 247711.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(74.6, 111.0]</td>\n",
       "      <td>(-1.001, 0.0]</td>\n",
       "      <td>(-0.0335, 0.0]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.133, 0.354]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(0.25, 0.485]</td>\n",
       "      <td>(0.689, 0.919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AL</td>\n",
       "      <td>(4467673.0, 5639632.0]</td>\n",
       "      <td>(195858.0, 247711.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(74.6, 111.0]</td>\n",
       "      <td>(-1.001, 0.0]</td>\n",
       "      <td>(-0.0335, 0.0]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.133, 0.354]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(0.485, 0.651]</td>\n",
       "      <td>(0.689, 0.919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AL</td>\n",
       "      <td>(4467673.0, 5639632.0]</td>\n",
       "      <td>(195858.0, 247711.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(74.6, 111.0]</td>\n",
       "      <td>(-1.001, 0.0]</td>\n",
       "      <td>(-0.0335, 0.0]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.354, 0.491]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(0.651, 0.791]</td>\n",
       "      <td>(0.347, 0.689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1269</td>\n",
       "      <td>WV</td>\n",
       "      <td>(1344212.0, 1792147.0]</td>\n",
       "      <td>(57106.0, 78270.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(63.4, 74.6]</td>\n",
       "      <td>(2.0, 4.0]</td>\n",
       "      <td>(0.195, 0.381]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.354, 0.491]</td>\n",
       "      <td>(3.0, 4.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(-0.968, -0.898]</td>\n",
       "      <td>(-0.44, -0.251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>WV</td>\n",
       "      <td>(1344212.0, 1792147.0]</td>\n",
       "      <td>(57106.0, 78270.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(63.4, 74.6]</td>\n",
       "      <td>(0.0, 1.0]</td>\n",
       "      <td>(0.0461, 0.102]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.354, 0.491]</td>\n",
       "      <td>(3.0, 4.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(-1.0, -0.968]</td>\n",
       "      <td>(-0.44, -0.251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271</td>\n",
       "      <td>WV</td>\n",
       "      <td>(1344212.0, 1792147.0]</td>\n",
       "      <td>(57106.0, 78270.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(63.4, 74.6]</td>\n",
       "      <td>(2.0, 4.0]</td>\n",
       "      <td>(0.195, 0.381]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.354, 0.491]</td>\n",
       "      <td>(5.0, 7.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(-1.0, -0.968]</td>\n",
       "      <td>(-0.251, -0.0506]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1272</td>\n",
       "      <td>WV</td>\n",
       "      <td>(1344212.0, 1792147.0]</td>\n",
       "      <td>(57106.0, 78270.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(63.4, 74.6]</td>\n",
       "      <td>(2.0, 4.0]</td>\n",
       "      <td>(0.195, 0.381]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.354, 0.491]</td>\n",
       "      <td>(5.0, 7.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(-1.0, -0.968]</td>\n",
       "      <td>(-0.0506, 0.151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1273</td>\n",
       "      <td>WV</td>\n",
       "      <td>(1344212.0, 1792147.0]</td>\n",
       "      <td>(57106.0, 78270.0]</td>\n",
       "      <td>(40151.999, 47346.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>(63.4, 74.6]</td>\n",
       "      <td>(16.75, 31.0]</td>\n",
       "      <td>(0.748, 1.44]</td>\n",
       "      <td>(-0.001, 3.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.354, 0.491]</td>\n",
       "      <td>(5.0, 7.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>(-0.968, -0.898]</td>\n",
       "      <td>(0.151, 0.347]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE ABBREVIATION              POPULATION TOTAL GDP LAST Q (X 1 MIL.)  \\\n",
       "0                    AL  (4467673.0, 5639632.0]        (195858.0, 247711.0]   \n",
       "1                    AL  (4467673.0, 5639632.0]        (195858.0, 247711.0]   \n",
       "2                    AL  (4467673.0, 5639632.0]        (195858.0, 247711.0]   \n",
       "3                    AL  (4467673.0, 5639632.0]        (195858.0, 247711.0]   \n",
       "4                    AL  (4467673.0, 5639632.0]        (195858.0, 247711.0]   \n",
       "...                 ...                     ...                         ...   \n",
       "1269                 WV  (1344212.0, 1792147.0]          (57106.0, 78270.0]   \n",
       "1270                 WV  (1344212.0, 1792147.0]          (57106.0, 78270.0]   \n",
       "1271                 WV  (1344212.0, 1792147.0]          (57106.0, 78270.0]   \n",
       "1272                 WV  (1344212.0, 1792147.0]          (57106.0, 78270.0]   \n",
       "1273                 WV  (1344212.0, 1792147.0]          (57106.0, 78270.0]   \n",
       "\n",
       "                GDP/CAPITA  IS BORDER STATE # RESIDENTS/SQUARE MILE  \\\n",
       "0     (40151.999, 47346.0]                0           (74.6, 111.0]   \n",
       "1     (40151.999, 47346.0]                0           (74.6, 111.0]   \n",
       "2     (40151.999, 47346.0]                0           (74.6, 111.0]   \n",
       "3     (40151.999, 47346.0]                0           (74.6, 111.0]   \n",
       "4     (40151.999, 47346.0]                0           (74.6, 111.0]   \n",
       "...                    ...              ...                     ...   \n",
       "1269  (40151.999, 47346.0]                0            (63.4, 74.6]   \n",
       "1270  (40151.999, 47346.0]                0            (63.4, 74.6]   \n",
       "1271  (40151.999, 47346.0]                0            (63.4, 74.6]   \n",
       "1272  (40151.999, 47346.0]                0            (63.4, 74.6]   \n",
       "1273  (40151.999, 47346.0]                0            (63.4, 74.6]   \n",
       "\n",
       "     # OF CONFIRMED CASES # OF CONFIRMED CASES PER 100K  \\\n",
       "0           (-1.001, 0.0]                (-0.0335, 0.0]   \n",
       "1           (-1.001, 0.0]                (-0.0335, 0.0]   \n",
       "2           (-1.001, 0.0]                (-0.0335, 0.0]   \n",
       "3           (-1.001, 0.0]                (-0.0335, 0.0]   \n",
       "4           (-1.001, 0.0]                (-0.0335, 0.0]   \n",
       "...                   ...                           ...   \n",
       "1269           (2.0, 4.0]                (0.195, 0.381]   \n",
       "1270           (0.0, 1.0]               (0.0461, 0.102]   \n",
       "1271           (2.0, 4.0]                (0.195, 0.381]   \n",
       "1272           (2.0, 4.0]                (0.195, 0.381]   \n",
       "1273        (16.75, 31.0]                 (0.748, 1.44]   \n",
       "\n",
       "     DAYS SINCE BAR/RESTAURANT LIMITS  \\\n",
       "0                       (-0.001, 3.0]   \n",
       "1                       (-0.001, 3.0]   \n",
       "2                       (-0.001, 3.0]   \n",
       "3                       (-0.001, 3.0]   \n",
       "4                       (-0.001, 3.0]   \n",
       "...                               ...   \n",
       "1269                    (-0.001, 3.0]   \n",
       "1270                    (-0.001, 3.0]   \n",
       "1271                    (-0.001, 3.0]   \n",
       "1272                    (-0.001, 3.0]   \n",
       "1273                    (-0.001, 3.0]   \n",
       "\n",
       "      DAYS SINCE CIVIL PREPAREDNESS EMERGENCY  ... PUBLIC HEALTH EMERGENCY  \\\n",
       "0                                           0  ...                       0   \n",
       "1                                           0  ...                       0   \n",
       "2                                           0  ...                       0   \n",
       "3                                           0  ...                       0   \n",
       "4                                           0  ...                       0   \n",
       "...                                       ...  ...                     ...   \n",
       "1269                                        0  ...                       1   \n",
       "1270                                        0  ...                       1   \n",
       "1271                                        0  ...                       1   \n",
       "1272                                        0  ...                       1   \n",
       "1273                                        0  ...                       1   \n",
       "\n",
       "      SCHOOL CLOSURES SECTION 1135 WAIVER WAIVE PRIOR AUTH  \\\n",
       "0                   0                   0                0   \n",
       "1                   0                   0                0   \n",
       "2                   0                   0                0   \n",
       "3                   0                   0                0   \n",
       "4                   0                   0                0   \n",
       "...               ...                 ...              ...   \n",
       "1269                1                   0                0   \n",
       "1270                1                   0                0   \n",
       "1271                1                   0                0   \n",
       "1272                1                   0                0   \n",
       "1273                1                   0                0   \n",
       "\n",
       "     NEW CASES PER 100K 15 DAYS LATER NUMBER OF ACTIVE NPIS DATE_month_sin  \\\n",
       "0                    (-0.0204, 0.133]         (-0.001, 1.0]       0.866025   \n",
       "1                      (0.133, 0.354]         (-0.001, 1.0]       1.000000   \n",
       "2                      (0.133, 0.354]         (-0.001, 1.0]       1.000000   \n",
       "3                      (0.133, 0.354]         (-0.001, 1.0]       1.000000   \n",
       "4                      (0.354, 0.491]         (-0.001, 1.0]       1.000000   \n",
       "...                               ...                   ...            ...   \n",
       "1269                   (0.354, 0.491]            (3.0, 4.0]       1.000000   \n",
       "1270                   (0.354, 0.491]            (3.0, 4.0]       1.000000   \n",
       "1271                   (0.354, 0.491]            (5.0, 7.0]       1.000000   \n",
       "1272                   (0.354, 0.491]            (5.0, 7.0]       1.000000   \n",
       "1273                   (0.354, 0.491]            (5.0, 7.0]       1.000000   \n",
       "\n",
       "     DATE_month_con      DATE_day_sin       DATE_day_con  \n",
       "0      5.000000e-01  (-0.651, -0.394]     (0.689, 0.919]  \n",
       "1      6.123234e-17    (-0.101, 0.25]      (0.919, 0.98]  \n",
       "2      6.123234e-17     (0.25, 0.485]     (0.689, 0.919]  \n",
       "3      6.123234e-17    (0.485, 0.651]     (0.689, 0.919]  \n",
       "4      6.123234e-17    (0.651, 0.791]     (0.347, 0.689]  \n",
       "...             ...               ...                ...  \n",
       "1269   6.123234e-17  (-0.968, -0.898]    (-0.44, -0.251]  \n",
       "1270   6.123234e-17    (-1.0, -0.968]    (-0.44, -0.251]  \n",
       "1271   6.123234e-17    (-1.0, -0.968]  (-0.251, -0.0506]  \n",
       "1272   6.123234e-17    (-1.0, -0.968]   (-0.0506, 0.151]  \n",
       "1273   6.123234e-17  (-0.968, -0.898]     (0.151, 0.347]  \n",
       "\n",
       "[1274 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example execution\n",
    "p = ProcessingC(steps={\n",
    "    'read_csv': \n",
    "        {'df': \"data/corona.csv\"},\n",
    "    'rename_columns': \n",
    "        {'columns': {}, 'uppercase': \"upper\"},\n",
    "    'drop_useless_feature': \n",
    "        {'columns': ['STATE']},\n",
    "    'to_date': {'n': 3},\n",
    "    'missing_values': {'method': \"median\"}, \n",
    "    'continuous_to_categorial': {'interval': 100, 'threshold': 10}\n",
    "}).fit()\n",
    "p.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
